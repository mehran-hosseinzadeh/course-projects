{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_project_phase1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNpjY9ntdJPr"
      },
      "source": [
        "**Mehran Hosseinzadeh**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6BAIzjFDhg8",
        "outputId": "e89bc117-25a9-429f-f7d6-8f42488db6b4"
      },
      "source": [
        "# Imports and setup\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "nltk.download(\"book\")\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from pandas import read_csv, to_numeric\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import linear_model \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import gensim\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rsnfiNT3AiJ"
      },
      "source": [
        "# module for preparing text according to three modes as mentioned\n",
        "def prepare_text(raw_text, mode):\n",
        "    if mode == 1:\n",
        "        return nltk.word_tokenize(raw_text)\n",
        "    prepared_text = re.sub(r'\\d+', '', raw_text)\n",
        "    prepared_text = \"\".join([char.lower() for char in prepared_text if char not in string.punctuation]) \n",
        "    tokens = nltk.word_tokenize(prepared_text)\n",
        "    if mode == 2:\n",
        "      return tokens\n",
        "    words = []\n",
        "    for w in tokens:\n",
        "      if w not in stop_words:\n",
        "        words.append(w)\n",
        "    stem_words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words]\n",
        "    return stem_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trxk2eN0HfN6"
      },
      "source": [
        "# reading data\n",
        "df = read_csv(\"dataset.csv\", encoding='utf-8', error_bad_lines=False, engine='python')\n",
        "X = df['comment'].to_numpy()\n",
        "Y = df['sentiment'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tp1zkEIRi56"
      },
      "source": [
        "# module for creating BoW according to desired mode.\n",
        "# if Train=True, the Vectorizer is fitted; else, the input is only transformed to the previously fitted global vectorizer\n",
        "def bow(X, mode, train):\n",
        "    sentences = []\n",
        "    i = 0\n",
        "    for x in X:\n",
        "        i+=1\n",
        "        if i % 3000 == 0:\n",
        "            print(\"Finisehd pre-processing of {} comments\".format(i))\n",
        "        words = prepare_text(x, mode)\n",
        "        sentences.append(\" \".join(words))\n",
        "    print(\"Creating Bag of Words.....\")\n",
        "    if train:\n",
        "        result = vectorizer.fit_transform(sentences)\n",
        "    else:\n",
        "        result = vectorizer.transform(sentences)\n",
        "    return np.array(result.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kBQpefz8EHt"
      },
      "source": [
        "# module for creatin word2vec according to desired mode\n",
        "def w2v(X, mode):\n",
        "    words = []\n",
        "    sentences = []\n",
        "    i = 0\n",
        "    for x in X:\n",
        "        i+=1\n",
        "        if i % 3000 == 0:\n",
        "            print(\"Finisehd pre-processing of {} comments\".format(i))\n",
        "        words.append(prepare_text(x, mode))\n",
        "        sentences.append(words[-1])\n",
        "    print(\"Fitting W2V.....\")\n",
        "    w2v_model = gensim.models.Word2Vec(sentences, min_count=1,size= 100,workers=3, window =3, sg = 1)\n",
        "    result = []\n",
        "    i = 0\n",
        "    for x in X:\n",
        "        if i % 3000 == 0:\n",
        "            print(\"Finisehd w2v for {} comments\".format(i))\n",
        "        result.append(sum([w2v_model.wv[word] for word in words[i]]) / len(x))\n",
        "        i+=1\n",
        "    return np.array(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFQo9SWWOqss",
        "outputId": "9a4b04b3-60d2-4607-8f74-1ea8d607e446"
      },
      "source": [
        "# creating Bow for train\n",
        "vectorizer = CountVectorizer(min_df=0.01, max_df=0.5)\n",
        "X_train_bow, X_test_bow, Y_train_bow, Y_test_bow = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_train_bow = bow(X_train_bow, 3, train=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Finisehd pre-processing of 12000 comments\n",
            "Finisehd pre-processing of 15000 comments\n",
            "Finisehd pre-processing of 18000 comments\n",
            "Finisehd pre-processing of 21000 comments\n",
            "Finisehd pre-processing of 24000 comments\n",
            "Finisehd pre-processing of 27000 comments\n",
            "Finisehd pre-processing of 30000 comments\n",
            "Finisehd pre-processing of 33000 comments\n",
            "Finisehd pre-processing of 36000 comments\n",
            "Creating Bag of Words.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCI6-ePFynAm",
        "outputId": "1c3a9579-c29b-4a6e-bf18-40907152d832"
      },
      "source": [
        "# creating Bow for test\n",
        "X_test_bow = bow(X_test_bow, 3, train=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Creating Bag of Words.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGyUF0AC0Fcu"
      },
      "source": [
        "# module to fit a model based on model_name\n",
        "def fit_model(X, Y, model_name):\n",
        "    if model_name == 'svm':\n",
        "        model = svm.LinearSVC(C=1)\n",
        "    elif model_name == 'knn':\n",
        "        model = KNeighborsClassifier(n_neighbors=7)\n",
        "    elif model_name == 'lr':\n",
        "        model = linear_model.LogisticRegression(warm_start=True, C=0.1)\n",
        "    model.fit(X, Y)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngqLiyECedG0"
      },
      "source": [
        "# analysis\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "def analysis(labels, predictions):\n",
        "    print(\"Classification Report:\\n\", classification_report(labels, predictions, target_names=['positive', 'negative']))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(labels, predictions))\n",
        "    print(\"Accuracy:\\n\", accuracy_score(labels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHH_dx6W0ot-"
      },
      "source": [
        "# initializang all needed modes for part 3.1\n",
        "Xs = {'train_bow_1': None, 'train_bow_2': None, 'train_bow_3': None, 'test_bow_1': None, 'test_bow_2': None, 'test_bow_3': None}\n",
        "Ys = {'train_bow_1': None, 'train_bow_2': None, 'train_bow_3': None, 'test_bow_1': None, 'test_bow_2': None, 'test_bow_3': None}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMod3sZ90dKp",
        "outputId": "bf6d47a8-eac7-457e-c371-96a5d54ef1a5"
      },
      "source": [
        "# filling in needed data for three modes for 3.1\n",
        "vectorizer = CountVectorizer(min_df=0.01, max_df=0.5)\n",
        "Xs['train_bow_1'], Xs['test_bow_1'], Ys['train_bow_1'], Ys['test_bow_1'] = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "Xs['train_bow_1'] = bow(Xs['train_bow_1'], 1, train=True)\n",
        "Xs['test_bow_1'] = bow(Xs['test_bow_1'], 1, train=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Finisehd pre-processing of 12000 comments\n",
            "Finisehd pre-processing of 15000 comments\n",
            "Finisehd pre-processing of 18000 comments\n",
            "Finisehd pre-processing of 21000 comments\n",
            "Finisehd pre-processing of 24000 comments\n",
            "Finisehd pre-processing of 27000 comments\n",
            "Finisehd pre-processing of 30000 comments\n",
            "Finisehd pre-processing of 33000 comments\n",
            "Finisehd pre-processing of 36000 comments\n",
            "Creating Bag of Words.....\n",
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Creating Bag of Words.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofng1laO3SUz",
        "outputId": "71a20ecc-4f3b-4b1f-cd48-e839c81c8419"
      },
      "source": [
        "# filling in needed data for three modes for 3.1\n",
        "vectorizer = CountVectorizer(min_df=0.01, max_df=0.5)\n",
        "Xs['train_bow_2'], Xs['test_bow_2'], Ys['train_bow_2'], Ys['test_bow_2'] = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "Xs['train_bow_2'] = bow(Xs['train_bow_2'], 2, train=True)\n",
        "Xs['test_bow_2'] = bow(Xs['test_bow_2'], 2, train=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Finisehd pre-processing of 12000 comments\n",
            "Finisehd pre-processing of 15000 comments\n",
            "Finisehd pre-processing of 18000 comments\n",
            "Finisehd pre-processing of 21000 comments\n",
            "Finisehd pre-processing of 24000 comments\n",
            "Finisehd pre-processing of 27000 comments\n",
            "Finisehd pre-processing of 30000 comments\n",
            "Finisehd pre-processing of 33000 comments\n",
            "Finisehd pre-processing of 36000 comments\n",
            "Creating Bag of Words.....\n",
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Creating Bag of Words.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3V4LLgw3gxU",
        "outputId": "8bb67d5d-a8ba-465c-ef44-bd2aa55150ba"
      },
      "source": [
        "# filling in needed data for three modes for 3.1\n",
        "vectorizer = CountVectorizer(min_df=0.01, max_df=0.5)\n",
        "Xs['train_bow_3'], Xs['test_bow_3'], Ys['train_bow_3'], Ys['test_bow_3'] = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "Xs['train_bow_3'] = bow(Xs['train_bow_3'], 3, train=True)\n",
        "Xs['test_bow_3'] = bow(Xs['test_bow_3'], 3, train=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Finisehd pre-processing of 12000 comments\n",
            "Finisehd pre-processing of 15000 comments\n",
            "Finisehd pre-processing of 18000 comments\n",
            "Finisehd pre-processing of 21000 comments\n",
            "Finisehd pre-processing of 24000 comments\n",
            "Finisehd pre-processing of 27000 comments\n",
            "Finisehd pre-processing of 30000 comments\n",
            "Finisehd pre-processing of 33000 comments\n",
            "Finisehd pre-processing of 36000 comments\n",
            "Creating Bag of Words.....\n",
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Creating Bag of Words.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r02MxSDZeA32"
      },
      "source": [
        "**3.1_part_A**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tszv7uUOyvIV",
        "outputId": "eb9ee976-e061-4342-e7dc-80dd2db95945"
      },
      "source": [
        "# 3.1_part_A\n",
        "models = {'svm_bow_1': None, 'svm_bow_2': None, 'svm_bow_3': None, 'lr_bow_1': None, 'lr_bow_2': None, 'lr_bow_3': None, 'knn_bow_1': None, 'knn_bow_2': None, 'knn_bow_3': None,}\n",
        "for mode in [1, 2, 3]:\n",
        "    for model_name in ['svm', 'lr', 'knn']:\n",
        "        print(\"Fitting {} on bow with pre-process mode: {}\".format(model_name, mode))\n",
        "        models['{0}_bow_{1}'.format(model_name, mode)] = fit_model(Xs['train_bow_{}'.format(mode)], Ys['train_bow_{}'.format(mode)], model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting svm on bow with pre-process mode: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting lr on bow with pre-process mode: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting knn on bow with pre-process mode: 1\n",
            "Fitting svm on bow with pre-process mode: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting lr on bow with pre-process mode: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting knn on bow with pre-process mode: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting svm on bow with pre-process mode: 3\n",
            "Fitting lr on bow with pre-process mode: 3\n",
            "Fitting knn on bow with pre-process mode: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D33PXQweGAq"
      },
      "source": [
        "**3.1_part_B**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XvgVz-Q6HBg",
        "outputId": "a76fdd9a-037c-46f7-daa0-5e4215c198f0"
      },
      "source": [
        "# 3.1_part_B\n",
        "for model_name in ['svm', 'lr', 'knn']:\n",
        "    for mode in [1, 2, 3]:\n",
        "        print(\"{0} results for bag of words wih pre-process mode {1}:\".format(model_name, mode))\n",
        "        analysis(list(Ys['test_bow_{}'.format(mode)]), list(models['{0}_bow_{1}'.format(model_name, mode)].predict(Xs['test_bow_{}'.format(mode)])))\n",
        "        print(\"####################################################\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svm results for bag of words wih pre-process mode 1:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.88      0.88      4508\n",
            "    negative       0.88      0.88      0.88      4492\n",
            "\n",
            "    accuracy                           0.88      9000\n",
            "   macro avg       0.88      0.88      0.88      9000\n",
            "weighted avg       0.88      0.88      0.88      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3952  556]\n",
            " [ 550 3942]]\n",
            "Accuracy:\n",
            " 0.8771111111111111\n",
            "####################################################\n",
            "svm results for bag of words wih pre-process mode 2:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.87      0.88      4508\n",
            "    negative       0.87      0.89      0.88      4492\n",
            "\n",
            "    accuracy                           0.88      9000\n",
            "   macro avg       0.88      0.88      0.88      9000\n",
            "weighted avg       0.88      0.88      0.88      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3926  582]\n",
            " [ 508 3984]]\n",
            "Accuracy:\n",
            " 0.8788888888888889\n",
            "####################################################\n",
            "svm results for bag of words wih pre-process mode 3:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.86      0.87      4508\n",
            "    negative       0.86      0.88      0.87      4492\n",
            "\n",
            "    accuracy                           0.87      9000\n",
            "   macro avg       0.87      0.87      0.87      9000\n",
            "weighted avg       0.87      0.87      0.87      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3874  634]\n",
            " [ 521 3971]]\n",
            "Accuracy:\n",
            " 0.8716666666666667\n",
            "####################################################\n",
            "lr results for bag of words wih pre-process mode 1:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.88      0.88      4508\n",
            "    negative       0.88      0.89      0.88      4492\n",
            "\n",
            "    accuracy                           0.88      9000\n",
            "   macro avg       0.88      0.88      0.88      9000\n",
            "weighted avg       0.88      0.88      0.88      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3949  559]\n",
            " [ 513 3979]]\n",
            "Accuracy:\n",
            " 0.8808888888888889\n",
            "####################################################\n",
            "lr results for bag of words wih pre-process mode 2:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.88      0.88      4508\n",
            "    negative       0.88      0.89      0.88      4492\n",
            "\n",
            "    accuracy                           0.88      9000\n",
            "   macro avg       0.88      0.88      0.88      9000\n",
            "weighted avg       0.88      0.88      0.88      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3958  550]\n",
            " [ 496 3996]]\n",
            "Accuracy:\n",
            " 0.8837777777777778\n",
            "####################################################\n",
            "lr results for bag of words wih pre-process mode 3:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.87      0.87      4508\n",
            "    negative       0.87      0.88      0.88      4492\n",
            "\n",
            "    accuracy                           0.87      9000\n",
            "   macro avg       0.87      0.87      0.87      9000\n",
            "weighted avg       0.87      0.87      0.87      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3905  603]\n",
            " [ 528 3964]]\n",
            "Accuracy:\n",
            " 0.8743333333333333\n",
            "####################################################\n",
            "knn results for bag of words wih pre-process mode 1:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.65      0.68      0.67      4508\n",
            "    negative       0.66      0.63      0.65      4492\n",
            "\n",
            "    accuracy                           0.66      9000\n",
            "   macro avg       0.66      0.66      0.66      9000\n",
            "weighted avg       0.66      0.66      0.66      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3076 1432]\n",
            " [1657 2835]]\n",
            "Accuracy:\n",
            " 0.6567777777777778\n",
            "####################################################\n",
            "knn results for bag of words wih pre-process mode 2:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.65      0.68      0.67      4508\n",
            "    negative       0.66      0.63      0.65      4492\n",
            "\n",
            "    accuracy                           0.66      9000\n",
            "   macro avg       0.66      0.66      0.66      9000\n",
            "weighted avg       0.66      0.66      0.66      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3087 1421]\n",
            " [1676 2816]]\n",
            "Accuracy:\n",
            " 0.6558888888888889\n",
            "####################################################\n",
            "knn results for bag of words wih pre-process mode 3:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.66      0.67      0.67      4508\n",
            "    negative       0.67      0.65      0.66      4492\n",
            "\n",
            "    accuracy                           0.66      9000\n",
            "   macro avg       0.66      0.66      0.66      9000\n",
            "weighted avg       0.66      0.66      0.66      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3029 1479]\n",
            " [1552 2940]]\n",
            "Accuracy:\n",
            " 0.6632222222222223\n",
            "####################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfm78vIV2CfV",
        "outputId": "5b7afb59-6577-4ec0-940b-f0949565020c"
      },
      "source": [
        "# creating word2vec structures\n",
        "X_w2v = w2v(X, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finisehd pre-processing of 3000 comments\n",
            "Finisehd pre-processing of 6000 comments\n",
            "Finisehd pre-processing of 9000 comments\n",
            "Finisehd pre-processing of 12000 comments\n",
            "Finisehd pre-processing of 15000 comments\n",
            "Finisehd pre-processing of 18000 comments\n",
            "Finisehd pre-processing of 21000 comments\n",
            "Finisehd pre-processing of 24000 comments\n",
            "Finisehd pre-processing of 27000 comments\n",
            "Finisehd pre-processing of 30000 comments\n",
            "Finisehd pre-processing of 33000 comments\n",
            "Finisehd pre-processing of 36000 comments\n",
            "Finisehd pre-processing of 39000 comments\n",
            "Finisehd pre-processing of 42000 comments\n",
            "Finisehd pre-processing of 45000 comments\n",
            "Fitting W2V.....\n",
            "Finisehd w2v for 3000 comments\n",
            "Finisehd w2v for 6000 comments\n",
            "Finisehd w2v for 9000 comments\n",
            "Finisehd w2v for 12000 comments\n",
            "Finisehd w2v for 15000 comments\n",
            "Finisehd w2v for 18000 comments\n",
            "Finisehd w2v for 21000 comments\n",
            "Finisehd w2v for 24000 comments\n",
            "Finisehd w2v for 27000 comments\n",
            "Finisehd w2v for 30000 comments\n",
            "Finisehd w2v for 33000 comments\n",
            "Finisehd w2v for 36000 comments\n",
            "Finisehd w2v for 39000 comments\n",
            "Finisehd w2v for 42000 comments\n",
            "Finisehd w2v for 45000 comments\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l6Wqync0qUX"
      },
      "source": [
        "# splitting word2vec for train and test\n",
        "X_train_w2v, X_test_w2v, Y_train_w2v, Y_test_w2v = train_test_split(X_w2v, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAFl45O3U4W-"
      },
      "source": [
        "# selecting hyperparameter from possible candidates using 5-fold by GridSearchCV\n",
        "def hyperparameter_cv(X, Y, model_name, model_params):\n",
        "    if model_name == 'svm':\n",
        "        model = svm.LinearSVC()\n",
        "    elif model_name == 'knn':\n",
        "        model = KNeighborsClassifier()\n",
        "    elif model_name == 'lr':\n",
        "        model = linear_model.LogisticRegression(warm_start=True)\n",
        "    elif model_name == 'mlp':\n",
        "        model = MLPClassifier(warm_start=True, max_iter=300)\n",
        "    clf = GridSearchCV(model, model_params, verbose=3)\n",
        "    clf.fit(X, Y)\n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKMoWLbLeL2c"
      },
      "source": [
        "**3.2_part_A**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljgxBbDD2lxf",
        "outputId": "4e60ba65-306a-4a43-cd20-93edf5bcd430"
      },
      "source": [
        "# 3.2_part_A\n",
        "# hyperparamtere selection for SVM with bag of words method\n",
        "print(\"Hyperparamtere selection for SVM with bag of words method\")\n",
        "\n",
        "clf = hyperparameter_cv(X_train_bow, Y_train_bow, 'svm', {'C': [0.1, 0.5, 1, 2, 5, 10, 15]})\n",
        "best_svm_bow = clf.best_estimator_\n",
        "best_svm_bow_params = clf.best_params_\n",
        "print(clf.best_params_)\n",
        "\n",
        "# hyperparamtere selection for LR with bag of words method\n",
        "print(\"Hyperparamtere selection for LR with bag of words method\")\n",
        "\n",
        "clf = hyperparameter_cv(X_train_bow, Y_train_bow, 'lr', {'C': [0.1, 0.5, 1, 2, 5, 10, 15]})\n",
        "best_lr_bow = clf.best_estimator_\n",
        "best_lr_bow_params = clf.best_params_\n",
        "print(clf.best_params_)\n",
        "\n",
        "# hyperparamtere selection for knn with bag of words method\n",
        "print(\"Hyperparamtere selection for KNN with bag of words method\")\n",
        "\n",
        "clf = hyperparameter_cv(X_train_bow, Y_train_bow, 'knn', {'n_neighbors': [3, 5, 7]})\n",
        "best_knn_bow = clf.best_estimator_\n",
        "best_knn_bow_params = clf.best_params_\n",
        "print(clf.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparamtere selection for SVM with bag of words method\n",
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.860, total=   8.0s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.865, total=   7.6s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.854, total=   7.4s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.860, total=   7.6s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.864, total=   7.6s\n",
            "[CV] C=0.5 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.5, score=0.859, total=   8.7s\n",
            "[CV] C=0.5 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.5, score=0.863, total=   8.4s\n",
            "[CV] C=0.5 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.5, score=0.855, total=   8.6s\n",
            "[CV] C=0.5 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.5, score=0.860, total=   8.2s\n",
            "[CV] C=0.5 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.5, score=0.864, total=   8.6s\n",
            "[CV] C=1 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=1, score=0.861, total=   9.0s\n",
            "[CV] C=1 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=1, score=0.862, total=   9.1s\n",
            "[CV] C=1 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=1, score=0.857, total=   9.3s\n",
            "[CV] C=1 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=1, score=0.858, total=   9.5s\n",
            "[CV] C=1 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=1, score=0.867, total=   9.4s\n",
            "[CV] C=2 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=2, score=0.862, total=  10.1s\n",
            "[CV] C=2 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=2, score=0.859, total=  10.2s\n",
            "[CV] C=2 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=2, score=0.858, total=  10.1s\n",
            "[CV] C=2 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=2, score=0.858, total=  10.2s\n",
            "[CV] C=2 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=2, score=0.865, total=  10.2s\n",
            "[CV] C=5 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=5, score=0.850, total=  11.4s\n",
            "[CV] C=5 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=5, score=0.856, total=  11.5s\n",
            "[CV] C=5 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=5, score=0.852, total=  11.4s\n",
            "[CV] C=5 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=5, score=0.855, total=  11.8s\n",
            "[CV] C=5 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=5, score=0.858, total=  11.8s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.852, total=  12.2s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.838, total=  12.0s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.841, total=  12.0s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.845, total=  12.1s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.852, total=  12.1s\n",
            "[CV] C=15 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=15, score=0.836, total=  12.1s\n",
            "[CV] C=15 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=15, score=0.841, total=  12.3s\n",
            "[CV] C=15 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=15, score=0.838, total=  12.1s\n",
            "[CV] C=15 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=15, score=0.829, total=  12.3s\n",
            "[CV] C=15 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  6.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=15, score=0.835, total=  12.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1}\n",
            "Hyperparamtere selection for LR with bag of words method\n",
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.863, total=   5.5s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.865, total=   5.1s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.860, total=   5.3s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.862, total=   5.5s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.869, total=   5.6s\n",
            "[CV] C=0.5 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.5, score=0.861, total=   7.4s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.864, total=   6.6s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.855, total=   6.3s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.861, total=   6.4s\n",
            "[CV] C=0.5 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.5, score=0.866, total=   7.5s\n",
            "[CV] C=1 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=1, score=0.861, total=   7.6s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.863, total=   6.4s\n",
            "[CV] C=1 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=1, score=0.855, total=   7.0s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.860, total=   7.3s\n",
            "[CV] C=1 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=1, score=0.866, total=   7.1s\n",
            "[CV] C=2 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=2, score=0.861, total=   7.5s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.863, total=   6.5s\n",
            "[CV] C=2 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=2, score=0.854, total=   7.4s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.859, total=   6.2s\n",
            "[CV] C=2 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=2, score=0.866, total=   7.4s\n",
            "[CV] C=5 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=5, score=0.860, total=   7.3s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.863, total=   7.1s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.854, total=   6.8s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.859, total=   6.5s\n",
            "[CV] C=5 .............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................. C=5, score=0.866, total=   7.4s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.860, total=   7.7s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.863, total=   7.2s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.854, total=   7.3s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.860, total=   7.2s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.865, total=   7.3s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.860, total=   6.9s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.863, total=   7.0s\n",
            "[CV] C=15 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=15, score=0.854, total=   7.1s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.860, total=   7.0s\n",
            "[CV] C=15 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  4.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=15, score=0.865, total=   7.3s\n",
            "{'C': 0.1}\n",
            "Hyperparamtere selection for KNN with bag of words method\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "[CV] n_neighbors=3 ...................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................... n_neighbors=3, score=0.616, total=11.4min\n",
            "[CV] n_neighbors=3 ...................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 11.4min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................... n_neighbors=3, score=0.633, total=11.4min\n",
            "[CV] n_neighbors=3 ...................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 22.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................... n_neighbors=3, score=0.638, total=11.4min\n",
            "[CV] n_neighbors=3 ...................................................\n",
            "[CV] ....................... n_neighbors=3, score=0.630, total=11.2min\n",
            "[CV] n_neighbors=3 ...................................................\n",
            "[CV] ....................... n_neighbors=3, score=0.663, total=11.3min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.636, total=11.4min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.641, total=11.3min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.676, total=11.3min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.642, total=11.3min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.674, total=11.3min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.651, total=11.4min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.651, total=11.4min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.687, total=11.3min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.656, total=11.3min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.684, total=11.2min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 169.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neighbors': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnD6hCLYeQXf"
      },
      "source": [
        "**3.2_part_B**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKtMaxWYOatb",
        "outputId": "e38326b3-edf3-487a-c1d1-8ed4433677b3"
      },
      "source": [
        "# 3.2_part_B\n",
        "# hyperparamtere selection for SVM with word2vec method\n",
        "print(\"Hyperparamtere selection for SVM with word2vec method\")\n",
        "\n",
        "clf = hyperparameter_cv(X_train_w2v, Y_train_w2v, 'svm', {'C': [0.1, 0.5, 1, 2, 5, 10, 15]})\n",
        "best_svm_w2v = clf.best_estimator_\n",
        "best_svm_w2v_params = clf.best_params_\n",
        "print(clf.best_params_)\n",
        "\n",
        "# hyperparamtere selection for LR with word2vec method\n",
        "print(\"Hyperparamtere selection for LR with word2vec method\")\n",
        "\n",
        "clf = hyperparameter_cv(X_train_w2v, Y_train_w2v, 'lr', {'C': [0.1, 0.5, 1, 2, 5, 10, 15]})\n",
        "best_lr_w2v = clf.best_estimator_\n",
        "best_lr_w2v_params = clf.best_params_\n",
        "print(clf.best_params_)\n",
        "\n",
        "# hyperparamtere selection for knn with word2vec method\n",
        "print(\"Hyperparamtere selection for knn with word2vec method\")\n",
        "\n",
        "clf = hyperparameter_cv(X_train_w2v, Y_train_w2v, 'knn', {'n_neighbors': [3, 5, 7]})\n",
        "best_knn_w2v = clf.best_estimator_\n",
        "best_knn_w2v_params = clf.best_params_\n",
        "print(clf.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparamtere selection for SVM with bag of words method\n",
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.804, total=   0.4s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.806, total=   0.4s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.801, total=   0.4s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.803, total=   0.4s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.810, total=   0.4s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.844, total=   0.6s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.845, total=   0.6s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.837, total=   0.6s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.839, total=   0.6s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.848, total=   0.6s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.854, total=   0.9s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.853, total=   0.9s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.849, total=   0.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.849, total=   0.9s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.855, total=   0.9s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.861, total=   1.2s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.858, total=   1.3s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.856, total=   1.2s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.855, total=   1.3s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.864, total=   1.2s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.862, total=   2.5s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.862, total=   2.5s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.860, total=   2.4s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.859, total=   2.5s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.864, total=   2.4s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.863, total=   4.2s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.864, total=   4.3s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.861, total=   4.3s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.860, total=   4.3s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.865, total=   4.2s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.862, total=   6.1s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.864, total=   5.9s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.861, total=   5.8s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.861, total=   5.9s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.865, total=   6.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 10}\n",
            "Hyperparamtere selection for LR with bag of words method\n",
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.759, total=   0.3s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.758, total=   0.3s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.759, total=   0.3s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.758, total=   0.3s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.764, total=   0.2s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.791, total=   0.3s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.790, total=   0.4s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.786, total=   0.2s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.792, total=   0.3s\n",
            "[CV] C=0.5 ...........................................................\n",
            "[CV] ............................... C=0.5, score=0.798, total=   0.3s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.807, total=   0.3s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.808, total=   0.3s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.807, total=   0.3s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.807, total=   0.3s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.815, total=   0.4s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.824, total=   0.4s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.827, total=   0.3s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.820, total=   0.5s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.822, total=   0.6s\n",
            "[CV] C=2 .............................................................\n",
            "[CV] ................................. C=2, score=0.830, total=   0.7s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.845, total=   0.7s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.845, total=   0.8s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.837, total=   0.5s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.840, total=   0.4s\n",
            "[CV] C=5 .............................................................\n",
            "[CV] ................................. C=5, score=0.849, total=   0.5s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.854, total=   0.7s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.852, total=   0.9s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.849, total=   0.9s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.849, total=   0.7s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.857, total=   1.1s\n",
            "[CV] C=15 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=15, score=0.858, total=   1.1s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.855, total=   0.9s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.853, total=   1.0s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.853, total=   1.1s\n",
            "[CV] C=15 ............................................................\n",
            "[CV] ................................ C=15, score=0.860, total=   0.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   19.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 15}\n",
            "Hyperparamtere selection for LR with bag of words method\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "[CV] n_neighbors=3 ...................................................\n",
            "[CV] ....................... n_neighbors=3, score=0.785, total= 1.2min\n",
            "[CV] n_neighbors=3 ...................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................... n_neighbors=3, score=0.784, total= 1.2min\n",
            "[CV] n_neighbors=3 ...................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.4min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................... n_neighbors=3, score=0.776, total= 1.2min\n",
            "[CV] n_neighbors=3 ...................................................\n",
            "[CV] ....................... n_neighbors=3, score=0.779, total= 1.2min\n",
            "[CV] n_neighbors=3 ...................................................\n",
            "[CV] ....................... n_neighbors=3, score=0.783, total= 1.2min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.797, total= 1.2min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.795, total= 1.2min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.787, total= 1.2min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.797, total= 1.2min\n",
            "[CV] n_neighbors=5 ...................................................\n",
            "[CV] ....................... n_neighbors=5, score=0.798, total= 1.2min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.805, total= 1.2min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.799, total= 1.2min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.798, total= 1.2min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.804, total= 1.1min\n",
            "[CV] n_neighbors=7 ...................................................\n",
            "[CV] ....................... n_neighbors=7, score=0.805, total= 1.2min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 17.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neighbors': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bX6GpANeSsL"
      },
      "source": [
        "**3.2_part_C**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01WaqGb5Lujk",
        "outputId": "7ea4d20e-dee7-43ec-af6c-8e84ed119b39"
      },
      "source": [
        "# 3.2_part_C\n",
        "print(\"SVM results for word2vec\")\n",
        "analysis(list(Y_test_w2v), list(best_svm_w2v.predict(X_test_w2v)))\n",
        "print(\"######################\")\n",
        "print(\"LR results for word2vec\")\n",
        "analysis(list(Y_test_w2v), list(best_lr_w2v.predict(X_test_w2v)))\n",
        "print(\"######################\")\n",
        "print(\"KNN results for word2vec\")\n",
        "analysis(list(Y_test_w2v), list(best_knn_w2v.predict(X_test_w2v)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM results for word2vec\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.87      0.86      0.86      4508\n",
            "    negative       0.86      0.87      0.86      4492\n",
            "\n",
            "    accuracy                           0.86      9000\n",
            "   macro avg       0.86      0.86      0.86      9000\n",
            "weighted avg       0.86      0.86      0.86      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3860  648]\n",
            " [ 588 3904]]\n",
            "Accuracy:\n",
            " 0.8626666666666667\n",
            "######################\n",
            "LR results for word2vec\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.86      0.85      0.86      4508\n",
            "    negative       0.85      0.86      0.86      4492\n",
            "\n",
            "    accuracy                           0.86      9000\n",
            "   macro avg       0.86      0.86      0.86      9000\n",
            "weighted avg       0.86      0.86      0.86      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3823  685]\n",
            " [ 609 3883]]\n",
            "Accuracy:\n",
            " 0.8562222222222222\n",
            "######################\n",
            "KNN results for word2vec\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.79      0.84      0.81      4508\n",
            "    negative       0.83      0.78      0.80      4492\n",
            "\n",
            "    accuracy                           0.81      9000\n",
            "   macro avg       0.81      0.81      0.81      9000\n",
            "weighted avg       0.81      0.81      0.81      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3784  724]\n",
            " [ 995 3497]]\n",
            "Accuracy:\n",
            " 0.809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgaLNfUPeWCD"
      },
      "source": [
        "**3.2_part_D**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oBcwBkq3UKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0db0bc-a481-4469-d203-1825f58852a2"
      },
      "source": [
        "# 3.2_part_D\n",
        "print(\"SVM results for bag of words\")\n",
        "analysis(list(Y_test_bow), list(best_svm_bow.predict(X_test_bow)))\n",
        "print(\"######################\")\n",
        "print(\"LR results for bag of words\")\n",
        "analysis(list(Y_test_bow), list(best_lr_bow.predict(X_test_bow)))\n",
        "print(\"######################\")\n",
        "print(\"KNN results for bag of words\")\n",
        "analysis(list(Y_test_bow), list(best_knn_bow.predict(X_test_bow)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM results for bag of words\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.86      0.87      4508\n",
            "    negative       0.86      0.89      0.87      4492\n",
            "\n",
            "    accuracy                           0.87      9000\n",
            "   macro avg       0.87      0.87      0.87      9000\n",
            "weighted avg       0.87      0.87      0.87      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3868  640]\n",
            " [ 514 3978]]\n",
            "Accuracy:\n",
            " 0.8717777777777778\n",
            "######################\n",
            "LR results for bag of words\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.87      0.87      4508\n",
            "    negative       0.87      0.88      0.88      4492\n",
            "\n",
            "    accuracy                           0.87      9000\n",
            "   macro avg       0.87      0.87      0.87      9000\n",
            "weighted avg       0.87      0.87      0.87      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3905  603]\n",
            " [ 528 3964]]\n",
            "Accuracy:\n",
            " 0.8743333333333333\n",
            "######################\n",
            "KNN results for bag of words\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.66      0.67      0.67      4508\n",
            "    negative       0.67      0.65      0.66      4492\n",
            "\n",
            "    accuracy                           0.66      9000\n",
            "   macro avg       0.66      0.66      0.66      9000\n",
            "weighted avg       0.66      0.66      0.66      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3029 1479]\n",
            " [1552 2940]]\n",
            "Accuracy:\n",
            " 0.6632222222222223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx1-jTlteXvp"
      },
      "source": [
        "**3.2_part_E**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM55-n3e3n0t"
      },
      "source": [
        "# 3.2_part_E\n",
        "import pickle\n",
        "\n",
        "pickle.dump(best_svm_w2v, open('best_svm_w2v.pkl', 'wb'))\n",
        "pickle.dump(best_lr_w2v, open('best_lr_w2v.pkl', 'wb'))\n",
        "pickle.dump(best_knn_w2v, open('best_knn_w2v.pkl', 'wb'))\n",
        "\n",
        "pickle.dump(best_svm_bow, open('best_svm_bow.pkl', 'wb'))\n",
        "pickle.dump(best_lr_bow, open('best_lr_bow.pkl', 'wb'))\n",
        "pickle.dump(best_knn_bow, open('best_knn_bow.pkl', 'wb'))\n",
        "\n",
        "pickle.dump(best_lr_bow, open('LR.pkl', 'wb'))\n",
        "pickle.dump(best_knn_bow, open('kNN.pkl', 'wb'))\n",
        "pickle.dump(best_svm_bow, open('SVM.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzD5MM4EeaVz"
      },
      "source": [
        "**3.3_part_A**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2crLT8NaSyt",
        "outputId": "a307c459-5671-4651-8a11-c46ad9021546"
      },
      "source": [
        "# 3.3_part_A\n",
        "# defining MLP with bag of words and 1 hidden layer. choosing proper hidden_layer_sizes and activation from GridSearchCV as before\n",
        "cv_params = {'hidden_layer_sizes': [(100,), (150,)], 'activation': ['tanh', 'relu']}\n",
        "clf = hyperparameter_cv(X_train_bow, Y_train_bow, 'mlp', cv_params)\n",
        "best_mlp_bow = clf.best_estimator_\n",
        "best_mlp_bow_params = clf.best_params_\n",
        "print(clf.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] activation=tanh, hidden_layer_sizes=(100,) ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, hidden_layer_sizes=(100,), score=0.859, total= 2.3min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(100,) ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, hidden_layer_sizes=(100,), score=0.859, total= 2.4min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(100,) ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.7min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation=tanh, hidden_layer_sizes=(100,), score=0.853, total= 2.3min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(100,) ......................\n",
            "[CV]  activation=tanh, hidden_layer_sizes=(100,), score=0.857, total= 2.3min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(100,) ......................\n",
            "[CV]  activation=tanh, hidden_layer_sizes=(100,), score=0.863, total= 2.3min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=tanh, hidden_layer_sizes=(150,), score=0.858, total= 3.0min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=tanh, hidden_layer_sizes=(150,), score=0.859, total= 3.1min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=tanh, hidden_layer_sizes=(150,), score=0.855, total= 3.1min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=tanh, hidden_layer_sizes=(150,), score=0.860, total= 3.1min\n",
            "[CV] activation=tanh, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=tanh, hidden_layer_sizes=(150,), score=0.860, total= 3.2min\n",
            "[CV] activation=relu, hidden_layer_sizes=(100,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(100,), score=0.863, total= 1.7min\n",
            "[CV] activation=relu, hidden_layer_sizes=(100,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(100,), score=0.860, total= 1.6min\n",
            "[CV] activation=relu, hidden_layer_sizes=(100,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(100,), score=0.854, total= 1.6min\n",
            "[CV] activation=relu, hidden_layer_sizes=(100,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(100,), score=0.858, total= 1.7min\n",
            "[CV] activation=relu, hidden_layer_sizes=(100,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(100,), score=0.861, total= 1.6min\n",
            "[CV] activation=relu, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(150,), score=0.861, total= 2.0min\n",
            "[CV] activation=relu, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(150,), score=0.862, total= 2.1min\n",
            "[CV] activation=relu, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(150,), score=0.856, total= 2.1min\n",
            "[CV] activation=relu, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(150,), score=0.862, total= 2.1min\n",
            "[CV] activation=relu, hidden_layer_sizes=(150,) ......................\n",
            "[CV]  activation=relu, hidden_layer_sizes=(150,), score=0.866, total= 2.1min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 45.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'relu', 'hidden_layer_sizes': (150,)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCZX8UWLecnl"
      },
      "source": [
        "3.3_part_B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HitKfrQJpQOf",
        "outputId": "d7a23535-4bb1-451d-a60c-0565a0dadb1b"
      },
      "source": [
        "# 3.3_part_B\n",
        "import pickle\n",
        "\n",
        "print(\"MLP results for bag of words\")\n",
        "analysis(list(Y_test_bow), list(best_mlp_bow.predict(X_test_bow)))\n",
        "print(\"######################\")\n",
        "pickle.dump(best_mlp_bow, open('best_mlp_bow.pkl', 'wb'))\n",
        "pickle.dump(best_mlp_bow, open('best.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP results for bag of words\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.87      0.87      0.87      4508\n",
            "    negative       0.87      0.87      0.87      4492\n",
            "\n",
            "    accuracy                           0.87      9000\n",
            "   macro avg       0.87      0.87      0.87      9000\n",
            "weighted avg       0.87      0.87      0.87      9000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3903  605]\n",
            " [ 573 3919]]\n",
            "Accuracy:\n",
            " 0.8691111111111111\n",
            "######################\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
